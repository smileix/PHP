dataset:
  name: MultiWOZ
  path: datasets/MultiWOZ
#  path: datasets/multiwoz_seen
#  path: datasets/multiwoz_unseen
  label_path_sep: '-' # label path separation token
  use_true_bio_label: False
#  domain: AddToPlaylist_0

plm:
  model_name: bert
  model_path: bert-base-uncased
#  model_name: roberta
#  model_path: roberta-base
#  model_path: /Work18/2020/weixiao/code/model/roberta/roberta_base

#  model_path: bert-large-uncased
  optimize:
    freeze_para: False
    lr: 0.00005
    weight_decay: 0.01
    scheduler:
      type:
      num_warmup_steps: 500

train:
  batch_size: 64
  num_epochs: 25
  early_stop: 5

test:
  batch_size: 64

dev:
  batch_size: 64

dataloader:
  max_seq_length: 100

template: mixed_template
#template: manual_template
#template: soft_template

#verbalizer: manual_verbalizer
verbalizer: soft_verbalizer

mixed_template:
  choice: 0
  file_path: scripts/MultiWOZ/template.txt
#  file_path: scripts/MultiWOZ/template_d.txt


manual_template:
  choice: 0
  file_path: scripts/MultiWOZ/template.txt

soft_template:
  choice: 0
  file_path: scripts/MultiWOZ/template.txt
  num_tokens: 20
  initialize_from_vocab: true
  random_range: 0.5
  optimize:
    name: AdamW
    lr: 0.03
    adam_epsilon: 1.0e-8
    scheduler:
      num_warmup_steps: 500



manual_verbalizer:
  choice: 0
  file_path: scripts/MultiWOZ/verbalizer.json

soft_verbalizer:
  parent_config: verbalizer
  choice: 0
  file_path: scripts/MultiWOZ/verbalizer.json
#  file_path: scripts/MultiWOZ/verbalizer_eg.json
#  file_path: scripts/MultiWOZ/verbalizer_eg_random.json
  num_classes: 34

classification:
  metric: ['seqeval']

environment:
  num_gpus: 1
  cuda_visible_devices:
    - 0
  local_rank: 0 

learning_setting: full

#few_shot:
#  parent_config: learning_setting
#  few_shot_sampling: sampling_from_train
#
#sampling_from_train:
#  parent_config: few_shot_sampling
#  num_examples_per_label: 8
#  also_sample_dev: True
#  num_examples_per_label_dev: 8
#  seed:
#    - 123

